# -*- coding: utf-8 -*-
__name = "Analisador de Viabilidade Geoespacial"
__author = "Valdean P. Souza & Gilmar Batista"
__version = "1.3.0"
__license = "CC BY-ND"

import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
import zipfile
import os
import fiona
import time
import uuid

#  -- Gerando UUID para n√£o repetir arquivo an√°lisado
id_unico = uuid.uuid4()
id_unico = str(id_unico).split('-', 2)
id_unico = id_unico[0]+id_unico[1]

# --- 1. CONFIGURA√á√ÉO (AJUSTE CONFORME NECESS√ÅRIO) ---
PASTA_DOS_KMZ = 'kmzs'
ARQUIVO_EXCEL_PONTOS = 'verificar_viabilidade.xlsx'
ARQUIVO_EXCEL_SAIDA = f'resultados/resultado_viabilidade-{id_unico}.xlsx'

# --- Nomes das colunas na sua planilha ---
COLUNA_LATITUDE = 'LATITUDE'
COLUNA_LONGITUDE = 'LONGITUDE'
COLUNA_COORDENADAS = 'COORDENADAS' # Coluna alternativa
COLUNA_VELOCIDADE = 'VELOCIDADE'
COLUNA_NOME_MANCHA = 'Name'

# --- Configura√ß√µes Geo ---
RAIO_PROXIMIDADE_METROS = .5 * 1000
CRS_GEOGRAFICO = "EPSG:4326"  # WGS84, padr√£o para lat/lon (KML/GPS)
CRS_PROJETADO = "EPSG:5880"   # SIRGAS 2000 / Brazil Polyconic, para c√°lculos em metros

# --- 2. FUN√á√ïES AUXILIARES ---
def print_header(name, author, version, license):
    """
    Imprime um cabe√ßalho estilizado e profissional no console.
    
    Args:
        name (str): nome do programa.
        author (str): nome do Autor.
        version (str): Vers√£o do Script
        license (str): Licen√ßa do Script

    """
    box_width = 80
    title = name

    # Monta as linhas do cabe√ßalho usando f-strings para centralizar e alinhar
    top_bottom_border = "=" * box_width
    separator = "|" + "-" * (box_width - 2) + "|"
    empty_line = "|" + " " * (box_width - 2) + "|"
    
    title_line = f"|{title:^{box_width - 2}}|"
    author_line = f"| {'Autor:':<10} {author:<{box_width - 14}} |"
    version_line = f"| {'Vers√£o:':<10} {version:<{box_width - 14}} |"
    license_line = f"| {'Licen√ßa:':<10} {license:<{box_width - 14}} |"

    # Imprime o cabe√ßalho completo com espa√ßamento
    print("\n" + top_bottom_border)
    print(empty_line)
    print(title_line)
    print(empty_line)
    print(separator)
    print(author_line)
    print(version_line)
    print(license_line)
    print(empty_line)
    print(top_bottom_border + "\n")

def extrair_todos_poligonos_do_kmz(arquivo_kmz):
    """ 
    Extrai os arquivos KMZ's para KML's na pasta TEMP caso ainda na esteja extraido
    Depois retorna os poligonos encontrados de cada arquivo extraido para KML
    
    Args:
        arquivo_kmz (str): caminho do arquivo KMZ encontrado.
    """
    basename = os.path.basename(arquivo_kmz).split('.')[0]
    temp_dir = os.path.join(PASTA_DOS_KMZ, "temp", basename)
    os.makedirs(temp_dir, exist_ok=True)
    caminho_kml = next((os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.lower().endswith('.kml')), None)
    if not caminho_kml:
        try:
            with zipfile.ZipFile(arquivo_kmz, 'r') as kmz:
                kml_filename = next((f for f in kmz.namelist() if f.lower().endswith('.kml')), None)
                if not kml_filename: return None
                print(f"‚ö†Ô∏è  Extraindo: '{os.path.basename(arquivo_kmz)}'")
                caminho_kml = kmz.extract(kml_filename, path=temp_dir)
        except Exception as e:
            print(f"‚ùå Erro ao extrair '{arquivo_kmz}': {e}")
            return None
    try:
        with fiona.Env():
            camadas = fiona.listlayers(caminho_kml)
        lista_de_gdfs = []
        for camada in camadas:
            try:
                gdf_camada = gpd.read_file(caminho_kml, driver='KML', layer=camada)
                gdf_camada = gdf_camada[gdf_camada.geometry.type.isin(['Polygon', 'MultiPolygon']) & gdf_camada.geometry.is_valid]
                if not gdf_camada.empty:
                    lista_de_gdfs.append(gdf_camada)
            except Exception:
                continue
        if not lista_de_gdfs: return None
        return gpd.GeoDataFrame(pd.concat(lista_de_gdfs, ignore_index=True), crs=CRS_GEOGRAFICO)
    except Exception as e:
        print(f"‚ùå Erro ao ler KML '{caminho_kml}': {e}")
        return None

def criar_ponto(row, mode):
    """
    Cria um objeto Point a partir de uma linha do DataFrame, com valida√ß√£o rigorosa.
    Retorna None se os dados forem inv√°lidos (vazios, 0 ou mal formatados).
    
    Args:
        row (pd.Series): A linha do DataFrame.
        mode (str): O modo de opera√ß√£o ('latlon' ou 'coords').
    """
    if mode == 'latlon':
        try:
            # Pega os valores
            lon = row[COLUNA_LONGITUDE]
            lat = row[COLUNA_LATITUDE]
            
            # VALIDA√á√ÉO: Verifica se s√£o nulos ou 0
            if pd.isna(lon) or pd.isna(lat) or lon == 0 or lat == 0:
                return None
            
            # Converte para float e cria o ponto
            return Point(float(lon), float(lat))
        except (ValueError, TypeError):
            return None # Retorna None se a convers√£o para float falhar

    elif mode == 'coords':
        try:
            # Pega o valor
            coords_str = row[COLUNA_COORDENADAS]
            
            # VALIDA√á√ÉO: Verifica se √© nulo, 0 ou uma string '0'
            if pd.isna(coords_str) or coords_str == 0 or str(coords_str).strip() == '0':
                return None
            
            # Processa a string de coordenadas
            coords = str(coords_str).replace(" ", "").split(',')
            if len(coords) == 2:
                lat, lon = map(float, coords)
                # VALIDA√á√ÉO extra para o caso de "0,0" na string
                if lat == 0 or lon == 0:
                    return None
                return Point(lon, lat)
        except (ValueError, TypeError, IndexError):
            return None # Retorna None se o formato for inv√°lido
    
    return None

# --- 3. C√ìDIGO DE PROCESSAMENTO OTIMIZADO ---
def analisar_viabilidade_otimizado():
    print("üê´ Iniciando an√°lise de viabilidade com agrega√ß√£o completa de resultados...")
    
    # Verificando se arquivo realmente existe ou foi exportado corretamente antes de prosseguir com o c√≥digo
    try:
        df_pontos = pd.read_excel(ARQUIVO_EXCEL_PONTOS)
    except FileNotFoundError:
        print(f"\n‚ùå ERRO: Arquivo '{ARQUIVO_EXCEL_PONTOS}' n√£o encontrado.")
        return
    
    # --- Etapa 1: Carregar pol√≠gonos (sem altera√ß√£o) ---
    print("\n[1/7] üó∫Ô∏è  Carregando e processando arquivos KMZ...")
    # (c√≥digo omitido para brevidade, √© o mesmo da vers√£o anterior)
    arquivos_kmz = [f for f in os.listdir(PASTA_DOS_KMZ) if f.lower().endswith('.kmz')]
    if not arquivos_kmz:
        print(f"‚ùå ERRO: Nenhum arquivo .kmz encontrado em '{PASTA_DOS_KMZ}'.")
        return
    lista_poligonos_gdfs = []
    for kmz_file in arquivos_kmz:
        caminho_completo = os.path.join(PASTA_DOS_KMZ, kmz_file)
        gdf_poligonos = extrair_todos_poligonos_do_kmz(caminho_completo)
        if gdf_poligonos is not None and not gdf_poligonos.empty:
            gdf_poligonos['Mancha'] = os.path.basename(kmz_file).split('.')[0]
            lista_poligonos_gdfs.append(gdf_poligonos)
    if not lista_poligonos_gdfs:
        print("‚ùå ERRO: Nenhum pol√≠gono v√°lido foi carregado dos arquivos KMZ.")
        return
    gdf_manchas_global = gpd.GeoDataFrame(pd.concat(lista_poligonos_gdfs, ignore_index=True), crs=CRS_GEOGRAFICO)
    if COLUNA_NOME_MANCHA not in gdf_manchas_global.columns:
        gdf_manchas_global[COLUNA_NOME_MANCHA] = 'Nome n√£o encontrado'
    else:
        gdf_manchas_global[COLUNA_NOME_MANCHA] = gdf_manchas_global[COLUNA_NOME_MANCHA].fillna('Nome n√£o encontrado')

    # --- Etapa 2: Carregar pontos e VALIDAR COLUNAS (sem altera√ß√£o) ---
    print("\n[2/7] üìç Lendo e validando o arquivo de coordenadas...")
    # (c√≥digo omitido para brevidade, √© o mesmo da vers√£o anterior)
    
    modo_coordenadas = None
    if COLUNA_LATITUDE in df_pontos.columns and COLUNA_LONGITUDE in df_pontos.columns:
        modo_coordenadas = 'latlon'
    elif COLUNA_COORDENADAS in df_pontos.columns:
        modo_coordenadas = 'coords'
    else:
        print(f"‚ùå ERRO FATAL: Nenhuma coluna de coordenada encontrada.")
        return

    # --- Etapa 3: Criar geometrias e separar pontos (sem altera√ß√£o) ---
    print("\n[3/7] üßê Validando cada ponto e criando geometrias...")
    # (c√≥digo omitido para brevidade, √© o mesmo da vers√£o anterior)
    df_pontos['geometry'] = df_pontos.apply(lambda row: criar_ponto(row, mode=modo_coordenadas), axis=1)
    invalidos_mask = df_pontos['geometry'].isna()
    df_invalidos = df_pontos[invalidos_mask].copy()
    df_validos = df_pontos[~invalidos_mask].copy()
    print(f"   -> {len(df_validos)} pontos v√°lidos para an√°lise.")
    print(f"   -> {len(df_invalidos)} pontos marcados como 'Coordenada Inv√°lida'.")
    
    resultados_geo = pd.DataFrame()
    if not df_validos.empty:
        gdf_pontos = gpd.GeoDataFrame(df_validos, geometry='geometry', crs=CRS_GEOGRAFICO)
        if COLUNA_VELOCIDADE in gdf_pontos.columns:
            gdf_pontos['velocidade_num'] = pd.to_numeric(
                gdf_pontos[COLUNA_VELOCIDADE].astype(str).str.extract(r'(\d+)')[0], errors='coerce').fillna(0)
        else:
            gdf_pontos['velocidade_num'] = 0

        # --- Etapa 4: An√°lise Espacial "DENTRO" e Agrega√ß√£o ---
        print("\n[4/7] ‚ö° Executando an√°lise 'DENTRO' e agregando resultados...")
        
        gdf_dentro_bruto = gpd.sjoin(gdf_pontos, gdf_manchas_global, how="inner", predicate="within")
        
        gdf_dentro_agregado = pd.DataFrame()
        if not gdf_dentro_bruto.empty:
            gdf_dentro_bruto['Status Viabilidade'] = gdf_dentro_bruto.apply(
                lambda row: 'Viabilidade Expressa' if row.velocidade_num <= 500 else 'Verificar PTP', axis=1)
            gdf_dentro_bruto['Dist√¢ncia (metros)'] = 0
            agg_rules = {
                'Mancha': lambda x: ', '.join(x.unique()),
                COLUNA_NOME_MANCHA: lambda x: ', '.join(x.unique()),
                'Status Viabilidade': 'first',
                'Dist√¢ncia (metros)': 'first'
            }
            gdf_dentro_agregado = gdf_dentro_bruto.groupby(gdf_dentro_bruto.index).agg(agg_rules)

        # --- Etapa 5: An√°lise "PR√ìXIMO" e Agrega√ß√£o ---
        print("\n[5/7] üõ∞Ô∏è  Executando an√°lise 'PR√ìXIMO' para os pontos restantes...")
        indices_encontrados = gdf_dentro_agregado.index
        gdf_pontos_fora = gdf_pontos.drop(indices_encontrados)
        
        gdf_proximos_agregado = pd.DataFrame()
        if not gdf_pontos_fora.empty and RAIO_PROXIMIDADE_METROS > 0:
            gdf_pontos_proj = gdf_pontos_fora.to_crs(CRS_PROJETADO)
            gdf_manchas_proj = gdf_manchas_global.to_crs(CRS_PROJETADO)
            
            # 1. Obter resultados brutos (com poss√≠veis duplicatas)
            gdf_proximos_bruto = gpd.sjoin_nearest(gdf_pontos_proj, gdf_manchas_proj, max_distance=RAIO_PROXIMIDADE_METROS, how="inner")
            
            if not gdf_proximos_bruto.empty:
                print("\n[6/7] üß¨ Agregando resultados de proximidade...")
                # 2. Calcular a dist√¢ncia para CADA correspond√™ncia bruta
                nearest_polygons = gdf_manchas_proj.loc[gdf_proximos_bruto['index_right'], 'geometry']
                aligned_polygons = gpd.GeoSeries(nearest_polygons.values, index=gdf_proximos_bruto.index, crs=CRS_PROJETADO)
                gdf_proximos_bruto['Dist√¢ncia (metros)'] = gdf_proximos_bruto.geometry.distance(aligned_polygons)
                gdf_proximos_bruto['Status Viabilidade'] = 'Pr√≥ximo √† mancha'

                # 3. Definir as regras de agrega√ß√£o para proximidade
                agg_rules_prox = {
                    'Mancha': lambda x: ', '.join(x.unique()),
                    COLUNA_NOME_MANCHA: lambda x: ', '.join(x.unique()),
                    'Status Viabilidade': 'first',
                    'Dist√¢ncia (metros)': 'min' # <-- Pega a MENOR dist√¢ncia
                }

                # 4. Agregar os resultados para garantir uma linha por ponto
                gdf_proximos_agregado = gdf_proximos_bruto.groupby(gdf_proximos_bruto.index).agg(agg_rules_prox)
                gdf_proximos_agregado['Dist√¢ncia (metros)'] = round(gdf_proximos_agregado['Dist√¢ncia (metros)'], 2)

        # --- Etapa 7: Consolidar e salvar o relat√≥rio final ---
        print("\n[7/7] üíæ Montando e salvando o relat√≥rio final...")
        
        # Junta os resultados dos agregados
        resultados_geo = pd.concat([
            gdf_dentro_agregado,
            gdf_proximos_agregado # Agora usamos o agregado aqui tamb√©m
        ]).rename(columns={COLUNA_NOME_MANCHA: 'Nome da Mancha'})

        df_final = df_pontos.merge(resultados_geo, left_index=True, right_index=True, how="left")
        df_final.loc[invalidos_mask, 'Status Viabilidade'] = 'Coordenada Inv√°lida'
        
        # df_final['Status Viabilidade'].fillna('Invi√°vel', inplace=True)
        df_final.fillna({'Status Viabilidade': 'Invi√°vel'}, inplace=True)

        df_final[['Mancha', 'Nome da Mancha']] = df_final[['Mancha', 'Nome da Mancha']].fillna('---')
        df_final = df_final.drop(columns=['geometry'], errors='ignore')

    try:
        print("\nüìä Resumo da An√°lise:")
        print(df_final['Status Viabilidade'].value_counts())
        
        df_final.to_excel(ARQUIVO_EXCEL_SAIDA, index=False, engine='openpyxl')
        
        print(f"\n‚úÖ Conclu√≠do! O resultado foi salvo em '{ARQUIVO_EXCEL_SAIDA}'.")
    except Exception as e:
        print(f"\n‚ùå ERRO ao salvar '{ARQUIVO_EXCEL_SAIDA}': {e}")

# --- Executa a fun√ß√£o principal ---
if __name__ == "__main__":

    # Imprime o cabe√ßalho no in√≠cio
    print_header(__name, __author, __version, __license)
    
    start_time = time.perf_counter()
    
    analisar_viabilidade_otimizado()
    end_time = time.perf_counter()
    duration = end_time - start_time
    print(f"\n‚è≥--- Tempo total de execu√ß√£o: {duration:.2f} segundos ---")